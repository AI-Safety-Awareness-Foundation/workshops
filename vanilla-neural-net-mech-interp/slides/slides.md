# Mechanistic Interpretability (Vanilla Neural Nets)

+ Assuming you know what a neural net is
+ What is mechanistic interpretability?
    - Interpretability: trying to find a way
    - Mechanistic: finding the specific, concrete mechanisms used
        * Ideally you could drill down to the per-neuron level

# What we're doing today

+ Going over

# Common themes of mechanistic interpretability

+ Finding mathematically equivalent or near-equivalent restructuring of an
  architecture
+ Proving causality

# Our object of study

+ Vanilla neural net (single hidden layer)
+ Much simpler than modern LLMs
+ But still complex enough to demonstrate the fundamental themes of mech interp

# What you'll be able to do at the end of the day

+ Thoroughly and mechanistically explain why the NN gets

# Standard way of thinking about a standard single hidden layer NN

+ There are two (three if you count inputs as neurons) layers of neurons
+ We pass iteratively from one layer to the next
+ Therefore to understand why 

# Reframe

+ 

# Challenging
