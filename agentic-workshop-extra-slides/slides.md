# Progress of AI agents

+ Agent scaffolding has been tried since GPT-3 in 2020
+ But the underlying LLM was too dumb then

# AI agents in 2020

+ Non-existent
+ If you tried, the underlying models would...
    * Regularly lost track of context
    * Would issue malformed tool calls
    * Incapable of even fairly simple logical deduction

# AI agents in 2025

+ Keeps track of context (on shorter contexts at least)
+ Very good at issuing tool calls (or at least self-correcting)
+ Starting to achieve long chains of logical deduction (e.g. gold IMO)
+ Still get lost on more complex tasks
    * But that might soon change?

# What changed?

+ The LLM got smarter because AI labs kept throwing money at the problem
+ And that's pretty much it!
    * Patterns that people had been trying since 2020 "magically" started working
    * No new "agentic" breakthrough, just the steady improvement of underlying models
    * So now everyone uses these patterns

# What does this mean for AI futures?

+ The basic design of LLMs have not changed
+ Smarter LLMs unlock a lot of new capabilities!
+ Also unlock a lot of new risks!
+ In the limit they could be an amazingly beneficial technology or a catastrophically damaging technology
+ "Country of geniuses in a datacenter"
    * Economic potential?
    * Huge societal transition?
    * Does this kill everyone?

